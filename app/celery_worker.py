from celery import Celery
import requests
import os
import openai
from openai import OpenAI
import logging

logger = logging.getLogger(__name__)

# âœ… í™˜ê²½ ë³€ìˆ˜ì—ì„œ Gorani ì„œë²„ URL ê°€ì ¸ì˜¤ê¸°
MODEL_SERVER_URL = os.getenv("MODEL_SERVER_URL")  # âœ… Gorani & LangGorani ëª¨ë¸ ì„œë²„
CELERY_BROKER_URL = os.getenv("CELERY_BROKER_URL")
CELERY_RESULT_BACKEND = os.getenv("CELERY_RESULT_BACKEND")
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")

celery_app = Celery(
    "translation_worker",
    backend=CELERY_RESULT_BACKEND,
    broker=CELERY_BROKER_URL
)

# âœ… Celery ì„¤ì • ì—…ë°ì´íŠ¸
celery_app.conf.update(
    task_ignore_result=False,  # ì‘ì—… ê²°ê³¼ë¥¼ ë¬´ì‹œí•˜ì§€ ì•Šë„ë¡ ì„¤ì •
    result_expires=3600  # ì‘ì—… ê²°ê³¼ ìœ ì§€ ì‹œê°„ (1ì‹œê°„)
)

# âœ… OpenAI í´ë¼ì´ì–¸íŠ¸ ê°ì²´ ìƒì„±
client = OpenAI(api_key=OPENAI_API_KEY)

# âœ… OpenAI ë²ˆì—­ ìš”ì²­ ì²˜ë¦¬
def translate_with_openai(text, source_lang, target_lang):
    try:
        response = client.chat.completions.create(
            model="gpt-4",
            messages=[
                {"role": "system", "content": f"Translate from {source_lang} to {target_lang}."},
                {"role": "user", "content": text}
            ]
        )
        return response.choices[0].message.content.strip()

    except openai.OpenAIError as e:
        logger.error(f"âŒ OpenAI API ì˜¤ë¥˜: {str(e)}")
        return f"OpenAI ë²ˆì—­ ì˜¤ë¥˜: {str(e)}"
    except Exception as e:
        logger.error(f"âŒ OpenAI ë²ˆì—­ ì‹¤íŒ¨: {str(e)}")
        return f"OpenAI ë²ˆì—­ ì‹¤íŒ¨: {str(e)}"

# âœ… Gorani & LangGorani ìš”ì²­ì„ ëª¨ë¸ ì„œë²„ë¡œ ì „ë‹¬
def request_model_server(text, source_lang, target_lang, model):
    try:
        # ëª¨ë¸ì— ë”°ë¼ ì˜¬ë°”ë¥¸ ì—”ë“œí¬ì¸íŠ¸ ì„¤ì •
        if model == "Gorani":
            endpoint = f"{MODEL_SERVER_URL}/translate/Gorani"
        elif model == "LangGorani":
            endpoint = f"{MODEL_SERVER_URL}/translate/LangGorani"
        else:
            return "âŒ ì§€ì›ë˜ì§€ ì•ŠëŠ” ëª¨ë¸ì…ë‹ˆë‹¤."

        payload = {"text": text, "source_lang": source_lang, "target_lang": target_lang, "model": model}
        headers = {"Content-Type": "application/json"}
        
        logger.info(f"ğŸ“¡ {model} ë²ˆì—­ ìš”ì²­ ì „ì†¡: {endpoint} | ë°ì´í„°: {payload}")

        response = requests.post(endpoint, json=payload, headers=headers, timeout=30)

        if response.status_code == 200:
            return response.json().get("answer", "ë²ˆì—­ ì‹¤íŒ¨")  # âœ… FastAPI ë¼ìš°í„°ì˜ ì‘ë‹µ í˜•ì‹ê³¼ ì¼ì¹˜í•´ì•¼ í•¨
        else:
            logger.error(f"âŒ ëª¨ë¸ ì„œë²„ ì˜¤ë¥˜ ({model}): {response.status_code}")
            return f"ëª¨ë¸ ì„œë²„ ì˜¤ë¥˜ ({model}): {response.status_code}"

    except requests.RequestException as e:
        logger.error(f"âŒ ëª¨ë¸ ì„œë²„ ì—°ê²° ì˜¤ë¥˜ ({model}): {str(e)}")
        return f"ëª¨ë¸ ì„œë²„ ì—°ê²° ì˜¤ë¥˜ ({model}): {str(e)}"


@celery_app.task(bind=True)
def translate_task(self, text, source_lang, target_lang, model):
    logger.info(f"ğŸš€ Celery Task ì‹¤í–‰: {model} ë²ˆì—­ ìš”ì²­")
    
    if model == "OpenAI":
        return translate_with_openai(text, source_lang, target_lang)
    elif model in ["Gorani", "LangGorani"]:
        result = request_model_server(text, source_lang, target_lang, model)
        logger.info(f"âœ… ë²ˆì—­ ê²°ê³¼ ({model}): {result}")
        return result
    else:
        return "ì§€ì›ë˜ì§€ ì•ŠëŠ” ëª¨ë¸ì…ë‹ˆë‹¤."